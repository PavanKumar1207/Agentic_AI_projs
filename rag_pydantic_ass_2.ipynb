{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b2dacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pydantic in k:\\agentic ai\\agentic_ai_env\\lib\\site-packages (from -r requirement.txt (line 1)) (2.11.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement python-doten (from versions: none)\n",
      "ERROR: No matching distribution found for python-doten\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e06f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72e461d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n",
    "# os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROK_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8463ca83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<groq.resources.chat.completions.Completions object at 0x000001EFBC7CCB90> async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001EFBCE28650> model_name='qwen-qwq-32b' model_kwargs={} groq_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model=\"qwen-qwq-32b\")\n",
    "\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb7906d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"\\n<think>\\nOkay, so I need to figure out what the capital of France is. Let's start by recalling what I know about France. France is a country in Western Europe, right? I remember learning about famous cities there like Paris, Lyon, Marseille, and maybe Bordeaux. But which one is the capital?\\n\\nHmm, I think Paris is the most well-known city in France. But wait, sometimes countries have capitals that aren't the most famous city. For example, I know that the capital of the United States is Washington D.C., not New York, which is bigger and more famous. But in France's case, I'm pretty sure Paris is the capital. Let me think of other examples. Like how London is the capital of the UK, even though cities like Birmingham or Manchester are big too. So maybe it's similar with Paris and France.\\n\\nI should also consider if there's any recent changes. I don't recall hearing about France moving their capital anywhere else. The Eiffel Tower, the Louvre, the French government buildings—those are all in Paris. The President of France, the Élysée Palace where they live, that's in Paris too. So that makes sense as the capital.\\n\\nWait, maybe there's some confusion with other countries. Like, is there a chance that someone might think Lyon or Marseille is the capital? Lyon is known for business and culture, but I don't think it's the capital. Marseille is a major port city. But again, I don't think it's the capital. The French Parliament meets in Paris, right? And the main landmarks like the Seine River, Notre-Dame Cathedral, they're all in Paris. \\n\\nAlso, in history, Paris has always been the center of French government and culture. It's been the capital for a long time. Even during times of war or occupation, Paris remained the capital. So unless there's some recent change, which I don't think there is, Paris is still the capital. \\n\\nLet me see if there's any other angle. Maybe looking at the country's administrative divisions. The capital is usually where the government is located. The President's office, the Prime Minister's office, the National Assembly and Senate—they should all be in the capital. Yes, I'm pretty confident that's all in Paris. \\n\\nAnother way to check: if I think of international events, like fashion weeks or major sports events, they often mention Paris as the host city for France. The French Open tennis tournament is in Paris. The Olympics were held there too, I believe. \\n\\nWait, maybe there's a trick question here? Like, was there a time when the capital was different? In the past, during the French Revolution or under Napoleon, was the capital moved? From what I remember, even during those times, Paris remained the capital. \\n\\nSo putting it all together, all the evidence points to Paris being the capital of France. I can't think of any reason to doubt that. I don't know of any official changes, and all the major institutions are there. Yeah, I'm pretty sure the answer is Paris.\\n</think>\\n\\nThe capital of France is **Paris**. \\n\\n**Key Points:**\\n- **Historical and Cultural Hub**: Paris has been the political and cultural heart of France for centuries, serving as the seat of government and home to iconic landmarks like the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral.\\n- **Government Institutions**: The French President resides at the Élysée Palace, and the National Assembly and Senate meet there, cementing its role as the administrative capital.\\n- **Global Recognition**: Known worldwide for art, fashion, and history, Paris is universally recognized as France's capital, with no recent changes to its status.\\n\\nThus, based on historical, political, and cultural evidence, Paris is unequivocally the capital of France.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 788, 'prompt_tokens': 17, 'total_tokens': 805, 'completion_time': 1.795401723, 'prompt_time': 0.002959119, 'queue_time': 0.264099972, 'total_time': 1.7983608420000001}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_a91d9c2cfb', 'finish_reason': 'stop', 'logprobs': None} id='run--ed97a28e-d2cb-43a9-844e-55a17c80e63a-0' usage_metadata={'input_tokens': 17, 'output_tokens': 788, 'total_tokens': 805}\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"What is the capital of France?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5b5a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a expert AI engineer. Provide a detailed answer to the question.\"),\n",
    "    (\"user\",\"{input}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96feae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42dea3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a expert AI engineer. Provide a detailed answer to the question.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001EFBC7CCB90>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001EFBCE28650>, model_name='qwen-qwq-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecb6b26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\\n<think>\\nOkay, so I need to explain what a neural network is. Hmm, where do I start? I remember that neural networks are inspired by the human brain\\'s structure, right? They have layers of nodes or neurons, kind of like how neurons in our brain are connected. But I\\'m a bit fuzzy on the specifics. Let me think step by step.\\n\\nFirst, maybe I should start with the basic components. There\\'s an input layer where data comes in, then maybe some hidden layers where the processing happens, and an output layer that gives the result. Activation functions must be involved to introduce non-linearity. Oh, and each connection between neurons has weights, which are adjusted during training. But how exactly do they learn?\\n\\nWait, the process of training involves adjusting the weights to minimize error. That\\'s probably through backpropagation. But what\\'s backpropagation exactly? It\\'s a method to calculate the gradient of the loss function with respect to the weights, right? And then using an optimization algorithm like gradient descent to update the weights.\\n\\nHmm, maybe I should structure this explanation into parts: structure, how they process information, learning through training, and maybe types of neural networks. Let me make sure I get the flow right.\\n\\nStarting with the structure: input layer, hidden layers, output layer. Each layer has neurons connected to the next layer. The input layer\\'s size depends on the data\\'s features. Then activation functions like ReLU, sigmoid, or tanh are used in each neuron to decide their output based on weighted inputs.\\n\\nThen, the forward pass: input data propagates through the network, each layer\\'s neurons compute a weighted sum plus a bias, then apply activation. The output is compared to the actual value, and the error is calculated (like MSE or cross-entropy loss).\\n\\nBackpropagation comes in here. The error is propagated back from the output layer to the input layer, adjusting the weights in reverse order. Using the chain rule to compute gradients. Then the weights are updated using gradient descent to reduce the loss over iterations (epochs).\\n\\nDifferent types of neural networks might include feedforward (which is the basic one I just described), recurrent networks (RNNs) for sequences, convolutional neural networks (CNNs) for image data, maybe autoencoders or generative adversarial networks (GANs). Each has different architectures suited for different tasks.\\n\\nWait, but maybe I should clarify the difference between neurons and nodes. Are they the same thing in this context? I think they are, the nodes in each layer represent neurons. The connections have weights, which are the parameters that the network learns.\\n\\nAlso, biases: each neuron has a bias term, which helps the model fit better by shifting the activation function. That\\'s an important part of the calculation.\\n\\nActivation functions are crucial because without them, the network would just be a linear combination, which can\\'t model complex functions. So the activation functions introduce non-linearity.\\n\\nTraining the neural network requires a dataset, which is split into training and validation sets. The network is trained iteratively, forward pass, compute loss, backpropagate, update weights. Over time, the network learns to make better predictions.\\n\\nRegularization techniques like dropout or L2 regularization might be used to prevent overfitting. Also, hyperparameters like learning rate, number of layers, number of neurons per layer, and activation functions need to be set before training.\\n\\nApplications: image recognition, natural language processing, predictions, etc. Each application uses a different architecture optimized for the task. CNNs excel in images because of their local connectivity and parameter sharing, while RNNs handle sequences by having loops for temporal dynamics.\\n\\nI should also mention that neural networks are part of deep learning when they have many hidden layers, hence deep neural networks. The term \"deep\" refers to the depth of layers beyond the input and output.\\n\\nWait, maybe I should clarify that a single hidden layer is a shallow network, while multiple hidden layers make it deep. Also, the concept of layers: input layer isn\\'t counted as hidden, so a network with two hidden layers is considered a deep network.\\n\\nActivation functions: ReLU is popular because it helps with vanishing gradient problems, whereas sigmoid or tanh were used before but suffer from saturation in deep networks.\\n\\nLoss functions: for regression, mean squared error; for classification, cross-entropy. The goal is to minimize the loss through backpropagation.\\n\\nOptimization algorithms: gradient descent, but more advanced versions like Adam, RMSProp, which adjust learning rates adaptively.\\n\\nPutting it all together, a neural network is a computational model that learns patterns in data by adjusting weights through training examples, using the backpropagation algorithm to optimize model parameters. The architecture can vary widely depending on the problem, and different components like activation functions and layer types (convolutional, recurrent, etc.) are chosen based on the task.\\n\\nI need to make sure I don\\'t forget any key components. Maybe start with a simple analogy, then break down the parts, explain forward and backward passes, and touch on training and types. Also mention how they\\'re used in real-world applications to show their utility. Avoid getting too technical, but still accurate.\\n</think>\\n\\nA neural network is a computational system inspired by the structure and function of the human brain. It is designed to recognize patterns, make decisions, or predict outcomes by learning from data. Here\\'s a detailed breakdown of its key components and processes:\\n\\n---\\n\\n### **1. Architecture of a Neural Network**\\nA neural network consists of interconnected layers of **nodes** (or *neurons*) organized into three main sections:\\n- **Input Layer**: The first layer that receives raw input data. The number of nodes here matches the number of input features (e.g., pixels in an image, words in text).\\n- **Hidden Layers**: One or more layers between the input and output. These layers perform computations and extract features from the data. The complexity of the model depends on the number and size of these layers.\\n- **Output Layer**: The final layer that produces the network’s prediction (e.g., class probabilities in classification, numerical values in regression).\\n\\n**Weights and Biases**:\\n- Each connection between nodes has a **weight**, which determines the importance of the input it receives.\\n- Each node also has a **bias** (a constant term) that allows the model to shift its activation function for better fit.\\n\\n---\\n\\n### **2. How a Neural Network Processes Information**\\nThe processing happens in two phases: **forward propagation** and **backpropagation**.\\n\\n#### **Forward Propagation**\\n1. **Input**: Data is fed into the input layer.\\n2. **Weighted Sum**: For each neuron in the next layer, a weighted sum of its inputs is calculated:  \\n   \\\\[\\n   z = \\\\sum (w_i \\\\cdot x_i) + b\\n   \\\\]  \\n   where \\\\( w_i \\\\) are weights, \\\\( x_i \\\\) are inputs, and \\\\( b \\\\) is the bias.\\n3. **Activation Function**: The weighted sum \\\\( z \\\\) is passed through an **activation function** to introduce non-linearity. Common activations include:\\n   - **ReLU**: \\\\( f(z) = \\\\max(0, z) \\\\)\\n   - **Sigmoid**: \\\\( f(z) = \\\\frac{1}{1 + e^{-z}} \\\\) (common for binary classification).\\n   - **Softmax**: Used in the output layer for multi-class classification to produce probabilities.\\n\\nThis process continues layer by layer until the output layer produces a prediction.\\n\\n---\\n\\n### **3. Learning Through Training**\\nNeural networks \"learn\" by adjusting weights and biases to minimize the error between predictions and actual outcomes. Here\\'s how this works:\\n\\n#### **Loss Function**\\nA **loss function** quantifies the error of the model’s predictions. Examples:\\n- **Mean Squared Error (MSE)** for regression:  \\n  \\\\[\\n  \\\\text{Loss} = \\\\frac{1}{N} \\\\sum (\\\\text{Predicted} - \\\\text{Actual})^2\\n  \\\\]\\n- **Cross-Entropy Loss** for classification:  \\n  \\\\[\\n  \\\\text{Loss} = -\\\\sum y \\\\cdot \\\\log(\\\\hat{y})\\n  \\\\]  \\n  where \\\\( y \\\\) is the true label and \\\\( \\\\hat{y} \\\\) is the predicted probability.\\n\\n#### **Backpropagation**\\nTo minimize the loss, the network uses the **backpropagation algorithm**:\\n1. Compute the gradient of the loss with respect to each weight (using the chain rule).\\n2. Adjust weights and biases in the opposite direction of the gradient using an **optimizer** (e.g., gradient descent, Adam, RMSProp) to update parameters:  \\n   \\\\[\\n   w_{\\\\text{new}} = w_{\\\\text{old}} - \\\\alpha \\\\cdot \\\\frac{\\\\partial \\\\text{Loss}}{\\\\partial w}\\n   \\\\]  \\n   where \\\\( \\\\alpha \\\\) is the **learning rate** (a hyperparameter controlling update step size).\\n\\nThis process repeats over iterations (epochs), gradually improving the model’s accuracy.\\n\\n---\\n\\n### **4. Key Components**\\n- **Activation Functions**: Essential for modeling complex, non-linear relationships. ReLU is widely used for hidden layers, while softmax is standard for classification outputs.\\n- **Layers**:\\n  - **Feedforward Networks (FFNs)**: Data flows in one direction (input → hidden → output).\\n  - **Convolutional Layers**: Specialized for spatial data (e.g., images) using filters (kernels) to detect features (used in CNNs).\\n  - **Recurrent Layers**: Handle sequential data (e.g., text, time series) by maintaining a \"memory\" through loops (e.g., LSTM, GRU networks).\\n- **Regularization**: Techniques like dropout (randomly ignoring nodes during training) or L2 regularization prevent overfitting.\\n\\n---\\n\\n### **5. Types of Neural Networks**\\n- **Feedforward Neural Network (FFNN)**: Simplest type, used for basic classification/regression tasks (e.g., predicting house prices).\\n- **Convolutional Neural Network (CNN)**: Dominates image and video analysis due to local connectivity and parameter sharing.\\n- **Recurrent Neural Network (RNN)**: Processes sequences (e.g., speech, text) by maintaining hidden states.\\n- **Generative Adversarial Network (GAN)**: Comprises two networks (generator and discriminator) for generating new data (e.g., images, videos).\\n- **Autoencoder**: Used for dimensionality reduction or anomaly detection, compressing and reconstructing data.\\n\\n---\\n\\n### **6. Training Process**\\n1. **Initialization**: Weights are initialized randomly, and biases may be set to zero or small values.\\n2. **Forward Pass**: Compute predictions and calculate the loss.\\n3. **Backward Pass (Backpropagation)**: Compute gradients of the loss with respect to each weight.\\n4. **Update**: Adjust weights using an optimizer.\\n5. **Repeat**: Iterate over the training data for multiple epochs, adjusting learning rate if needed.\\n\\n---\\n\\n### **7. Applications**\\nNeural networks power modern AI systems in:\\n- **Image Recognition** (CNNs in self-driving cars, medical imaging).\\n- **Natural Language Processing** (RNNs/LSTMs for machine translation, chatbots).\\n- **Game Playing** (Deep Reinforcement Learning in AlphaGo).\\n- **Anomaly Detection** (autoencoders in fraud detection).\\n\\n---\\n\\n### **8. Challenges and Considerations**\\n- **Overfitting**: Occurs when the model memorizes training data; addressed via regularization, dropout, or more data.\\n- **Vanishing/Exploding Gradients**: Issues in deep networks where gradients become too small/large during backpropagation. Solutions include activation functions like ReLU and gradient clipping.\\n- **Hyperparameter Tuning**: Learning rate, number of layers, and activation functions require careful selection.\\n\\n---\\n\\n### **9. Simplified Example**\\nImagine classifying cat vs. dog images:\\n- Input layer: Pixel values (e.g., 64×64×3 = 12,288 nodes).\\n- Hidden layers (CNN): Filters detect edges → textures → higher-level features (e.g., ears, fur patterns).\\n- Output layer (softmax): 2 nodes → probabilities for \"cat\" or \"dog\".\\n\\n---\\n\\n### **Summary**\\nA neural network is a flexible, hierarchical function approximator. By adjusting weights through backpropagation, it learns intricate relationships in data. Its power lies in its layered architecture and non-linear activation functions, enabling it to solve complex tasks from image recognition to language translation. The key to success lies in selecting the right architecture, hyperparameters, and training regimen for the problem at hand.\\n\\nFor deeper understanding, explore specific architectures (CNN, RNN) or dive into advanced topics like attention mechanisms (e.g., Transformers) used in models like GPT.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 2643, 'prompt_tokens': 40, 'total_tokens': 2683, 'completion_time': 6.035024469, 'prompt_time': 0.003955149, 'queue_time': 0.267095601, 'total_time': 6.038979618}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_28178d7ff6', 'finish_reason': 'stop', 'logprobs': None} id='run--6da20e88-76ce-45ab-90f4-35f13b6ab4e3-0' usage_metadata={'input_tokens': 40, 'output_tokens': 2643, 'total_tokens': 2683}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"input\":\"Can you explain the concept of a neural network?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "978b3aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'JavaScript', 'Java', 'C++', 'C# ']\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Setup your model\n",
    "llm = ChatGroq(\n",
    "    model=\"gemma2-9b-it\"\n",
    ")\n",
    "\n",
    "# Output parser for comma-separated list\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "# Prompt with explicit instruction\n",
    "prompt = f\"\"\"\n",
    "List five popular programming languages **only as a comma-separated list**.\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "# Ask the model\n",
    "response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "# Parse the response\n",
    "parsed = parser.parse(response.content)\n",
    "print(parsed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62888aeb",
   "metadata": {},
   "source": [
    "### Assisgment:\n",
    "Create a simple assistant that uses any LLM and should be pydantic, when we ask about any product it should give you two information product Name, product details tentative price in USD (integer). use chat Prompt Template.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8a0fd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Samsung Galaxy S24' price=799.99 description='The Samsung Galaxy S24 is a flagship smartphone featuring a powerful processor, vibrant display, and advanced camera system.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Step 1: Define the Pydantic model\n",
    "class Product(BaseModel):\n",
    "    name: str = Field(description=\"The name of the product\")\n",
    "    price: float = Field(description=\"The price of the product in USD\")\n",
    "    description: str = Field(description=\"A brief description of the product\")\n",
    "\n",
    "# Step 2: Initialize your LLM\n",
    "llm = ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "# Step 3: Setup output parser\n",
    "parser = PydanticOutputParser(pydantic_object=Product)\n",
    "\n",
    "# Step 4: Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that provides product information.\"),\n",
    "    (\"user\", \"Provide details about the following product: {product}.\\n{format_instructions}\")\n",
    "])\n",
    "\n",
    "# Step 5: Chain prompt + model + parser\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "\n",
    "product_query = \"Samsung Galaxy S24\"\n",
    "result = chain.invoke({\"product\": product_query, \"format_instructions\": parser.get_format_instructions()})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "197700f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"description\": \"The name of the product\", \"title\": \"Name\", \"type\": \"string\"}, \"price\": {\"description\": \"The price of the product in USD\", \"title\": \"Price\", \"type\": \"number\"}, \"description\": {\"description\": \"A brief description of the product\", \"title\": \"Description\", \"type\": \"string\"}}, \"required\": [\"name\", \"price\", \"description\"]}\\n```'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f96c138f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a YAML instance that conforms to the given JSON schema below.\\n\\n# Examples\\n## Schema\\n```\\n{\"title\": \"Players\", \"description\": \"A list of players\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Player\"}, \"definitions\": {\"Player\": {\"title\": \"Player\", \"type\": \"object\", \"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"Player name\", \"type\": \"string\"}, \"avg\": {\"title\": \"Avg\", \"description\": \"Batting average\", \"type\": \"number\"}}, \"required\": [\"name\", \"avg\"]}}}\\n```\\n## Well formatted instance\\n```\\n- name: John Doe\\n  avg: 0.3\\n- name: Jane Maxfield\\n  avg: 1.4\\n```\\n\\n## Schema\\n```\\n{\"properties\": {\"habit\": { \"description\": \"A common daily habit\", \"type\": \"string\" }, \"sustainable_alternative\": { \"description\": \"An environmentally friendly alternative to the habit\", \"type\": \"string\"}}, \"required\": [\"habit\", \"sustainable_alternative\"]}\\n```\\n## Well formatted instance\\n```\\nhabit: Using disposable water bottles for daily hydration.\\nsustainable_alternative: Switch to a reusable water bottle to reduce plastic waste and decrease your environmental footprint.\\n``` \\n\\nPlease follow the standard YAML formatting conventions with an indent of 2 spaces and make sure that the data types adhere strictly to the following JSON schema: \\n```\\n{\"properties\": {\"name\": {\"description\": \"The name of the product\", \"title\": \"Name\", \"type\": \"string\"}, \"price\": {\"description\": \"The price of the product in USD\", \"title\": \"Price\", \"type\": \"number\"}, \"description\": {\"description\": \"A brief description of the product\", \"title\": \"Description\", \"type\": \"string\"}}, \"required\": [\"name\", \"price\", \"description\"]}\\n```\\n\\nMake sure to always enclose the YAML output in triple backticks (```). Please do not add anything other than valid YAML output!'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import YamlOutputParser\n",
    "YamlOutputParser(pydantic_object=Product).get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f96a591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
